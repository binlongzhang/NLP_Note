{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-Hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "import joblib\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'词汇1','词汇2','词汇3'}\n",
    "t = Tokenizer(num_words=None,char_level=False)\n",
    "t.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇3 的one-hot编码为： [1, 0, 0]\n",
      "词汇2 的one-hot编码为： [0, 1, 0]\n",
      "词汇1 的one-hot编码为： [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "for token in vocab:\n",
    "    zero_list = [0]*len(vocab)\n",
    "    token_index = t.texts_to_sequences([token])[0][0]-1\n",
    "    zero_list[token_index] = 1\n",
    "    print(token,'的one-hot编码为：',zero_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/Tokenizer']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用joblib工具保存映射器，以便于之后使用\n",
    "tokenizer_path = '../models/Tokenizer'\n",
    "joblib.dump(t,tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 装载并使用\n",
    "import joblib\n",
    "t = joblib.load(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇1 的one-hot编码为： [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "token = '词汇1'\n",
    "token_index = t.texts_to_sequences([token])[0][0] - 1\n",
    "zero_list = [0]*len(vocab)\n",
    "zero_list[token_index] = 1\n",
    "print(token,'的one-hot编码为：',zero_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用fasttext训练词向量模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "model = fasttext.train_unsupervised('data/fil9','skipgram',dim=100,epoch=5,lr=0.01,thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得对应单词的词向量\n",
    "model.get_word_vector('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_nearest_neighbors('sports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存\n",
    "model.save_model('fil9.bin')\n",
    "# 模型装载\n",
    "model.load_model('fil9.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过tensorboard可视化词嵌入模型(有bug，待修正)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "df =  pd.read_csv(\"../data/vocab100.csv\",sep=' ')\n",
    "word = df['word'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('../log/wordEmbedding')\n",
    "# 随机化一个矩阵，默认其为词嵌入模型矩阵\n",
    "embedded = torch.randn(100,50)\n",
    "meta = list(map(lambda x:x.strip(),word))\n",
    "writer.add_embedding(embedded,metadata=meta)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sentimentAnalysis]",
   "language": "python",
   "name": "conda-env-sentimentAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
